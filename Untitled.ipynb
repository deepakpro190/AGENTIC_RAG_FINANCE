{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f56d0b6b-fe90-410a-a9a8-8b92def9009d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline, BitsAndBytesConfig\n",
    "import torch\n",
    "from langchain_huggingface import HuggingFacePipeline  # ‚úÖ Updated import\n",
    "\n",
    "# Model ID\n",
    "model_id = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "\n",
    "# 1Ô∏è‚É£ Set up `bitsandbytes` quantization\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,  # Use 4-bit quantization\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "# 2Ô∏è‚É£ Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "# 3Ô∏è‚É£ Load model with quantization\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",    # Automatically assign to GPU\n",
    "    quantization_config=bnb_config  # Use 4-bit quantization\n",
    ")\n",
    "\n",
    "# 4Ô∏è‚É£ Create Hugging Face pipeline (üö® Removed `device=0`)\n",
    "hf_pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    return_full_text=False  # Set to True if needed\n",
    ")\n",
    "\n",
    "# 5Ô∏è‚É£ Wrap in LangChain (‚úÖ Using the new module)\n",
    "llm = HuggingFacePipeline(pipeline=hf_pipeline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c75a3f55-ca63-4cfe-a5b5-63f729f359ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Mar 15 00:07:37 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 571.96                 Driver Version: 571.96         CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3050 ...  WDDM  |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   58C    P8              5W /   90W |    2263MiB /   6144MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A            9776      C   ...onda3\\envs\\finance\\python.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c09d133e-09fa-4a77-b355-35309da5c933",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Stocks: When you buy a stock, the company will transfer ownership to your account. Bonds: A bond essentially means lending money with interest attached but has no ownership rights that people have when they sell another one of those paper-thin things for which they pay an agreed price called payment on demand. \n",
      "One more key difference is there are two types of bonds such as  U.S., British etc bonds where it can take from $100 million to millions dollars if paid in full so we often hear many times that much! So each class may follow different rules like compound or simple rates.\n",
      "There is also something else regarding bonds - there's only certain amount of time to get them sold once bought before their death dates (or expiration date) or not available anymore due to age/loss interest/maintenance/reputation etc. The reason for this specific constraint goes back to how bonds work, namely ‚Äì what was first ever discovered about life after centuries ago by economists mathematicians scientists philosophers & inventors  according  to Henry Morgan. People might wonder why some of these very conditions were never observed yet did most investors do this kind? Every business needs a big plan but even then, sometimes it is hard just because nobody knows anything!\n",
      "In addition, Some investments involving small ones may become risk-ier; some smaller securities actually increase our chances or put us at greater stakes than larger quantities given earlier mentioned statements making better sense through understanding all aspects related investments i am glad having shared my insight helping to create trust between whom the person who holds said funds made while speaking over various topics sharing real-world practical information I would now want to add that whenever any particular security issue discussed during say other talks session meetings conference meeting discussions going further forward into details share thoughts ideas within own community however here discussion turns out topic toward end with closing next chapter call for actions desired need to discuss others questions throughout journey\n",
      "I hope this helps clarify some points related to both businesses. Keep learning and asking the right question if you feel unsure don't hesitate reaching anyone anywhere especially the financial advisors expert witnesses law enforcement professionals or medical personnel who'd be able help address whatever query raises or keep searching until someone knowledgeable provides assist or guidance based upon individual circumstances.\n",
      "\n",
      "Regarding investment options:\n",
      "Some popular methods for investing money include:\n",
      "1. **Stocks**: Buying shares directly\n",
      "2. **Mutual Funds**: Investing via mutual fund management\n",
      "3. **Exchange-Traded Funds** ([ETF]): Using traded exchange-listed listed assets\n",
      "4. **Retirement Accounts:** Individuals use accounts designated for retirement plans or saving personal money using tax credits\n",
      "\n",
      "This concludes exploring valuable insights around stocks, bonds,and possibly new categories including index options market-specific opportunities designed exclusively benefiting high net worth individuals looking beyond traditional thinking today learn whole concepts explore meaning connecting history mathematics statistics mechanics.\n",
      "\n",
      "Let me know if you're ready to go forward discussing case study examples cases highlighting strategies advice sought seek assistance.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline, BitsAndBytesConfig\n",
    "from langchain_huggingface import HuggingFacePipeline  \n",
    "\n",
    "# Load Model & Tokenizer\n",
    "model_id = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "bnb_config = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_compute_dtype=torch.float16)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, device_map=\"auto\", quantization_config=bnb_config)\n",
    "\n",
    "# Hugging Face Pipeline with Optimized Settings\n",
    "hf_pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    return_full_text=False,\n",
    "    do_sample=True,               # Enable sampling for longer outputs\n",
    "    max_new_tokens=2000,          # Significantly increase token length\n",
    "    top_p=0.95,                   # Diverse output\n",
    "    temperature=1.1,              # More variation in responses\n",
    "    repetition_penalty=1.2        # Reduce redundancy\n",
    ")\n",
    "\n",
    "# Wrap in LangChain\n",
    "llm = HuggingFacePipeline(pipeline=hf_pipeline)\n",
    "\n",
    "# Function for generating extended responses\n",
    "def generate_long_text(prompt):\n",
    "    torch.cuda.empty_cache()  # Clear VRAM\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "    response = llm.invoke(prompt)\n",
    "    return response\n",
    "\n",
    "# Example Query\n",
    "query = \"Difference between stocks and bonds .\"\n",
    "output = generate_long_text(query)\n",
    "\n",
    "# Print formatted output\n",
    "print(\"\\n\".join(output.split(\"\\n\\n\")))  # Ensure paragraph formatting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1cb2186-f141-4746-96fa-76735b48017d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu121\n",
      "True\n",
      "NVIDIA GeForce RTX 3050 6GB Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)  \n",
    "print(torch.cuda.is_available())  # Should return True\n",
    "print(torch.cuda.get_device_name(0))  # Should print your GPU name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d5ecd07-653a-4640-b16b-f17d6316e01b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu121\n",
      "True\n",
      "NVIDIA GeForce RTX 3050 6GB Laptop GPU\n",
      "0.20.1+cu121\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "print(torch.__version__)  \n",
    "print(torch.cuda.is_available())  # Should return True if GPU is detected\n",
    "print(torch.cuda.get_device_name(0))  # Should show your GPU name\n",
    "print(torchvision.__version__)  # Should print torchvision version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91795ad8-7f29-4139-8c4c-15747688a031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"object\":\"list\",\"data\":[{\"id\":\"ministral-3b-2410\",\"object\":\"model\",\"created\":1742216611,\"owned_by\":\"mistralai\",\"capabilities\":{\"completion_chat\":true,\"completion_fim\":false,\"function_calling\":true,\"fine_tuning\":true,\"vision\":false},\"name\":\"ministral-3b-2410\",\"description\":\"Official ministral-3b-2410 Mistral AI model\",\"max_context_length\":131072,\"aliases\":[\"ministral-3b-latest\"],\"deprecation\":null,\"default_model_temperature\":0.3,\"type\":\"base\"},{\"id\":\"ministral-3b-latest\",\"object\":\"model\",\"created\":1742216611,\"owned_by\":\"mistralai\",\"capabilities\":{\"completion_chat\":true,\"completion_fim\":false,\"function_calling\":true,\"fine_tuning\":true,\"vision\":false},\"name\":\"ministral-3b-2410\",\"description\":\"Official ministral-3b-2410 Mistral AI model\",\"max_context_length\":131072,\"aliases\":[\"ministral-3b-2410\"],\"deprecation\":null,\"default_model_temperature\":0.3,\"type\":\"base\"},{\"id\":\"ministral-8b-2410\",\"object\":\"model\",\"created\":1742216611,\"owned_by\":\"mistralai\",\"capabilities\":{\"completion_chat\":true,\"completion_fim\":false,\"function_calling\":true,\"fine_tuning\":false,\"vision\":false},\"name\":\"ministral-8b-2410\",\"description\":\"Official ministral-8b-2410 Mistral AI model\",\"max_context_length\":131072,\"aliases\":[\"ministral-8b-latest\"],\"deprecation\":null,\"default_model_temperature\":0.3,\"type\":\"base\"},{\"id\":\"ministral-8b-latest\",\"object\":\"model\",\"created\":1742216611,\"owned_by\":\"mistralai\",\"capabilities\":{\"completion_chat\":true,\"completion_fim\":false,\"function_calling\":true,\"fine_tuning\":false,\"vision\":false},\"name\":\"ministral-8b-2410\",\"description\":\"Official ministral-8b-2410 Mistral AI model\",\"max_context_length\":131072,\"aliases\":[\"ministral-8b-2410\"],\"deprecation\":null,\"default_model_temperature\":0.3,\"type\":\"base\"},{\"id\":\"open-mistral-7b\",\"object\":\"model\",\"created\":1742216611,\"owned_by\":\"mistralai\",\"capabilities\":{\"completion_chat\":true,\"completion_fim\":false,\"function_calling\":true,\"fine_tuning\":false,\"vision\":false},\"name\":\"open-mistral-7b\",\"description\":\"Official open-mistral-7b Mistral AI model\",\"max_context_length\":32768,\"aliases\":[\"mistral-tiny\",\"mistral-tiny-2312\"],\"deprecation\":null,\"default_model_temperature\":0.7,\"type\":\"base\"},{\"id\":\"mistral-tiny\",\"object\":\"model\",\"created\":1742216611,\"owned_by\":\"mistralai\",\"capabilities\":{\"completion_chat\":true,\"completion_fim\":false,\"function_calling\":true,\"fine_tuning\":false,\"vision\":false},\"name\":\"open-mistral-7b\",\"description\":\"Official open-mistral-7b Mistral AI model\",\"max_context_length\":32768,\"aliases\":[\"open-mistral-7b\",\"mistral-tiny-2312\"],\"deprecation\":null,\"default_model_temperature\":0.7,\"type\":\"base\"},{\"id\":\"mistral-tiny-2312\",\"object\":\"model\",\"created\":1742216611,\"owned_by\":\"mistralai\",\"capabilities\":{\"completion_chat\":true,\"completion_fim\":false,\"function_calling\":true,\"fine_tuning\":false,\"vision\":false},\"name\":\"open-mistral-7b\",\"description\":\"Official open-mistral-7b Mistral AI model\",\"max_context_length\":32768,\"aliases\":[\"open-mistral-7b\",\"mistral-tiny\"],\"deprecation\":null,\"default_model_temperature\":0.7,\"type\":\"base\"},{\"id\":\"open-mistral-nemo\",\"object\":\"model\",\"created\":1742216611,\"owned_by\":\"mistralai\",\"capabilities\":{\"completion_chat\":true,\"completion_fim\":false,\"function_calling\":true,\"fine_tuning\":true,\"vision\":false},\"name\":\"open-mistral-nemo\",\"description\":\"Official open-mistral-nemo Mistral AI model\",\"max_context_length\":131072,\"aliases\":[\"open-mistral-nemo-2407\",\"mistral-tiny-2407\",\"mistral-tiny-latest\"],\"deprecation\":null,\"default_model_temperature\":0.3,\"type\":\"base\"},{\"id\":\"open-mistral-nemo-2407\",\"object\":\"model\",\"created\":1742216611,\"owned_by\":\"mistralai\",\"capabilities\":{\"completion_chat\":true,\"completion_fim\":false,\"function_calling\":true,\"fine_tuning\":true,\"vision\":false},\"name\":\"open-mistral-nemo\",\"description\":\"Official open-mistral-nemo Mistral AI model\",\"max_context_length\":131072,\"aliases\":[\"open-mistral-nemo\",\"mistral-tiny-2407\",\"mistral-tiny-latest\"],\"deprecation\":null,\"default_model_temperature\":0.3,\"type\":\"base\"},{\"id\":\"mistral-tiny-2407\",\"object\":\"model\",\"created\":1742216611,\"owned_by\":\"mistralai\",\"capabilities\":{\"completion_chat\":true,\"completion_fim\":false,\"function_calling\":true,\"fine_tuning\":true,\"vision\":false},\"name\":\"open-mistral-nemo\",\"description\":\"Official open-mistral-nemo Mistral AI model\",\"max_context_length\":131072,\"aliases\":[\"open-mistral-nemo\",\"open-mistral-nemo-2407\",\"mistral-tiny-latest\"],\"deprecation\":null,\"default_model_temperature\":0.3,\"type\":\"base\"},{\"id\":\"mistral-tiny-latest\",\"object\":\"model\",\"created\":1742216611,\"owned_by\":\"mistralai\",\"capabilities\":{\"completion_chat\":true,\"completion_fim\":false,\"function_calling\":true,\"fine_tuning\":true,\"vision\":false},\"name\":\"open-mistral-nemo\",\"description\":\"Official open-mistral-nemo Mistral AI model\",\"max_context_length\":131072,\"aliases\":[\"open-mistral-nemo\",\"open-mistral-nemo-2407\",\"mistral-tiny-2407\"],\"deprecation\":null,\"default_model_temperature\":0.3,\"type\":\"base\"},{\"id\":\"open-mixtral-8x7b\",\"object\":\"model\",\"created\":1742216611,\"owned_by\":\"mistralai\",\"capabilities\":{\"completion_chat\":true,\"completion_fim\":false,\"function_calling\":true,\"fine_tuning\":false,\"vision\":false},\"name\":\"open-mixtral-8x7b\",\"description\":\"Official open-mixtral-8x7b Mistral AI model\",\"max_context_length\":32768,\"aliases\":[\"mistral-small\",\"mistral-small-2312\"],\"deprecation\":null,\"default_model_temperature\":0.7,\"type\":\"base\"},{\"id\":\"mistral-small\",\"object\":\"model\",\"created\":1742216611,\"owned_by\":\"mistralai\",\"capabilities\":{\"completion_chat\":true,\"completion_fim\":false,\"function_calling\":true,\"fine_tuning\":false,\"vision\":false},\"name\":\"open-mixtral-8x7b\",\"description\":\"Official open-mixtral-8x7b Mistral AI model\",\"max_context_length\":32768,\"aliases\":[\"open-mixtral-8x7b\",\"mistral-small-2312\"],\"deprecation\":null,\"default_model_temperature\":0.7,\"type\":\"base\"},{\"id\":\"mistral-small-2312\",\"object\":\"model\",\"created\":1742216611,\"owned_by\":\"mistralai\",\"capabilities\":{\"completion_chat\":true,\"completion_fim\":false,\"function_calling\":true,\"fine_tuning\":false,\"vision\":false},\"name\":\"open-mixtral-8x7b\",\"description\":\"Official open-mixtral-8x7b Mistral AI model\",\"max_context_length\":32768,\"aliases\":[\"open-mixtral-8x7b\",\"mistral-small\"],\"deprecation\":null,\"default_model_temperature\":0.7,\"type\":\"base\"},{\"id\":\"open-mixtral-8x22b\",\"object\":\"model\",\"created\":1742216611,\"owned_by\":\"mistralai\",\"capabilities\":{\"completion_chat\":true,\"completion_fim\":false,\"function_calling\":true,\"fine_tuning\":false,\"vision\":false},\"name\":\"open-mixtral-8x22b\",\"description\":\"Official open-mixtral-8x22b Mistral AI model\",\"max_context_length\":65536,\"aliases\":[\"open-mixtral-8x22b-2404\"],\"deprecation\":null,\"default_model_temperature\":0.7,\"type\":\"base\"},{\"id\":\"open-mixtral-8x22b-2404\",\"object\":\"model\",\"created\":1742216611,\"owned_by\":\"mistralai\",\"capabilities\":{\"completion_chat\":true,\"completion_fim\":false,\"function_calling\":true,\"fine_tuning\":false,\"vision\":false},\"name\":\"open-mixtral-8x22b\",\"description\":\"Official open-mixtral-8x22b Mistral AI model\",\"max_context_length\":65536,\"aliases\":[\"open-mixtral-8x22b\"],\"deprecation\":null,\"default_model_temperature\":0.7,\"type\":\"base\"},{\"id\":\"mistral-small-2402\",\"object\":\"model\",\"created\":1742216611,\"owned_by\":\"mistralai\",\"capabilities\":{\"completion_chat\":true,\"completion_fim\":false,\"function_calling\":true,\"fine_tuning\":true,\"vision\":false},\"name\":\"mistral-small-2402\",\"description\":\"Official mistral-small-2402 Mistral AI model\",\"max_context_length\":32768,\"aliases\":[],\"deprecation\":null,\"default_model_temperature\":0.7,\"type\":\"base\"},{\"id\":\"mistral-small-2409\",\"object\":\"model\",\"created\":1742216611,\"owned_by\":\"mistralai\",\"capabilities\":{\"completion_chat\":true,\"completion_fim\":false,\"function_calling\":true,\"fine_tuning\":true,\"vision\":false},\"name\":\"mistral-small-2409\",\"description\":\"Official mistral-small-2409 Mistral AI model\",\"max_context_length\":32768,\"aliases\":[],\"deprecation\":null,\"default_model_temperature\":0.7,\"type\":\"base\"},{\"id\":\"mistral-medium-2312\",\"object\":\"model\",\"created\":1742216611,\"owned_by\":\"mistralai\",\"capabilities\":{\"completion_chat\":true,\"completion_fim\":false,\"function_calling\":true,\"fine_tuning\":false,\"vision\":false},\"name\":\"mistral-medium-2312\",\"description\":\"Official mistral-medium-2312 Mistral AI model\",\"max_context_length\":32768,\"aliases\":[\"mistral-medium\",\"mistral-medium-latest\"],\"deprecation\":null,\"default_model_temperature\":0.7,\"type\":\"base\"},{\"id\":\"mistral-medium\",\"object\":\"model\",\"created\":1742216611,\"owned_by\":\"mistralai\",\"capabilities\":{\"completion_chat\":true,\"completion_fim\":false,\"function_calling\":true,\"fine_tuning\":false,\"vision\":false},\"name\":\"mistral-medium-2312\",\"description\":\"Official mistral-medium-2312 Mistral AI model\",\"max_context_length\":32768,\"aliases\":[\"mistral-medium-2312\",\"mistral-medium-latest\"],\"deprecation\":null,\"default_model_temperature\":0.7,\"type\":\"base\"},{\"id\":\"mistral-medium-latest\",\"object\":\"model\",\"created\":1742216611,\"owned_by\":\"mistralai\",\"capabilities\":{\"completion_chat\":true,\"completion_fim\":false,\"function_calling\":true,\"fine_tuning\":false,\"vision\":false},\"name\":\"mistral-medium-2312\",\"description\":\"Official mistral-medium-2312 Mistral AI model\",\"max_context_length\":32768,\"aliases\":[\"mistral-medium-2312\",\"mistral-medium\"],\"deprecation\":null,\"default_model_temperature\":0.7,\"type\":\"base\"},{\"id\":\"mistral-large-2402\",\"object\":\"model\",\"created\":1742216611,\"owned_by\":\"mistralai\",\"capabilities\":{\"completion_chat\":true,\"completion_fim\":false,\"function_calling\":true,\"fine_tuning\":false,\"vision\":false},\"name\":\"mistral-large-2402\",\"description\":\"Official mistral-large-2402 Mistral AI model\",\"max_context_length\":32768,\"aliases\":[],\"deprecation\":null,\"default_model_temperature\":0.7,\"type\":\"base\"},{\"id\":\"mistral-large-2407\",\"object\":\"model\",\"created\":1742216611,\"owned_by\":\"mistralai\",\"capabilities\":{\"completion_chat\":true,\"completion_fim\":false,\"function_calling\":true,\"fine_tuning\":true,\"vision\":false},\"name\":\"mistral-large-2407\",\"description\":\"Official mistral-large-2407 Mistral AI model\",\"max_context_length\":131072,\"aliases\":[],\"deprecation\":null,\"default_model_temperature\":0.7,\"type\":\"base\"},{\"id\":\"mistral-large-2411\",\"object\":\"model\",\"created\":1742216611,\"owned_by\":\"mistralai\",\"capabilities\":{\"completion_chat\":true,\"completion_fim\":false,\"function_calling\":true,\"fine_tuning\":true,\"vision\":false},\"name\":\"mistral-large-2411\",\"description\":\"Official mistral-large-2411 Mistral AI model\",\"max_context_length\":131072,\"aliases\":[\"mistral-large-latest\"],\"deprecation\":null,\"default_model_temperature\":0.7,\"type\":\"base\"},{\"id\":\"mistral-large-latest\",\"object\":\"model\",\"created\":1742216611,\"owned_by\":\"mistralai\",\"capabilities\":{\"completion_chat\":true,\"completion_fim\":false,\"function_calling\":true,\"fine_tuning\":true,\"vision\":false},\"name\":\"mistral-large-2411\",\"description\":\"Official mistral-large-2411 Mistral AI model\",\"max_context_length\":131072,\"aliases\":[\"mistral-large-2411\"],\"deprecation\":null,\"default_model_temperature\":0.7,\"type\":\"base\"},{\"id\":\"pixtral-large-2411\",\"object\":\"model\",\"created\":1742216611,\"owned_by\":\"mistralai\",\"capabilities\":{\"completion_chat\":true,\"completion_fim\":false,\"function_calling\":true,\"fine_tuning\":false,\"vision\":true},\"name\":\"pixtral-large-2411\",\"description\":\"Official pixtral-large-2411 Mistral AI model\",\"max_context_length\":131072,\"aliases\":[\"pixtral-large-latest\",\"mistral-large-pixtral-2411\"],\"deprecation\":null,\"default_model_temperature\":0.7,\"type\":\"base\"},{\"id\":\"pixtral-large-latest\",\"object\":\"model\",\"created\":1742216611,\"owned_by\":\"mistralai\",\"capabilities\":{\"completion_chat\":true,\"completion_fim\":false,\"function_calling\":true,\"fine_tuning\":false,\"vision\":true},\"name\":\"pixtral-large-2411\",\"description\":\"Official pixtral-large-2411 Mistral AI model\",\"max_context_length\":131072,\"aliases\":[\"pixtral-large-2411\",\"mistral-large-pixtral-2411\"],\"deprecation\":null,\"default_model_temperature\":0.7,\"type\":\"base\"},{\"id\":\"mistral-large-pixtral-2411\",\"object\":\"model\",\"created\":1742216611,\"owned_by\":\"mistralai\",\"capabilities\":{\"completion_chat\":true,\"completion_fim\":false,\"function_calling\":true,\"fine_tuning\":false,\"vision\":true},\"name\":\"pixtral-large-2411\",\"description\":\"Official pixtral-large-2411 Mistral AI model\",\"max_context_length\":131072,\"aliases\":[\"pixtral-large-2411\",\"pixtral-large-latest\"],\"deprecation\":null,\"default_model_temperature\":0.7,\"type\":\"base\"},{\"id\":\"codestral-2405\",\"object\":\"model\",\"created\":1742216611,\"owned_by\":\"mistralai\",\"capabilities\":{\"completion_chat\":true,\"completion_fim\":true,\"function_calling\":true,\"fine_tuning\":true,\"vision\":false},\"name\":\"codestral-2405\",\"description\":\"Official codestral-2405 Mistral AI model\",\"max_context_length\":32768,\"aliases\":[],\"deprecation\":null,\"default_model_temperature\":0.7,\"type\":\"base\"},{\"id\":\"codestral-2501\",\"object\":\"model\",\"created\":1742216611,\"owned_by\":\"mistralai\",\"capabilities\":{\"completion_chat\":true,\"completion_fim\":true,\"function_calling\":true,\"fine_tuning\":false,\"vision\":false},\"name\":\"codestral-2501\",\"description\":\"Official codestral-2501 Mistral AI model\",\"max_context_length\":262144,\"aliases\":[\"codestral-latest\",\"codestral-2412\",\"codestral-2411-rc5\"],\"deprecation\":null,\"default_model_temperature\":0.3,\"type\":\"base\"},{\"id\":\"codestral-latest\",\"object\":\"model\",\"created\":1742216611,\"owned_by\":\"mistralai\",\"capabilities\":{\"completion_chat\":true,\"completion_fim\":true,\"function_calling\":true,\"fine_tuning\":false,\"vision\":false},\"name\":\"codestral-2501\",\"description\":\"Official codestral-2501 Mistral AI model\",\"max_context_length\":262144,\"aliases\":[\"codestral-2501\",\"codestral-2412\",\"codestral-2411-rc5\"],\"deprecation\":null,\"default_model_temperature\":0.3,\"type\":\"base\"},{\"id\":\"codestral-2412\",\"object\":\"model\",\"created\":1742216611,\"owned_by\":\"mistralai\",\"capabilities\":{\"completion_chat\":true,\"completion_fim\":true,\"function_calling\":true,\"fine_tuning\":false,\"vision\":false},\"name\":\"codestral-2501\",\"description\":\"Official codestral-2501 Mistral AI model\",\"max_context_length\":262144,\"aliases\":[\"codestral-2501\",\"codestral-latest\",\"codestral-2411-rc5\"],\"deprecation\":null,\"default_model_temperature\":0.3,\"type\":\"base\"},{\"id\":\"codestral-2411-rc5\",\"object\":\"model\",\"created\":1742216611,\"owned_by\":\"mistralai\",\"capabilities\":{\"completion_chat\":true,\"completion_fim\":true,\"function_calling\":true,\"fine_tuning\":false,\"vision\":false},\"name\":\"codestral-2501\",\"description\":\"Official codestral-2501 Mistral AI model\",\"max_context_length\":262144,\"aliases\":[\"codestral-2501\",\"codestral-latest\",\"codestral-2412\"],\"deprecation\":null,\"default_model_temperature\":0.3,\"type\":\"base\"},{\"id\":\"codestral-mamba-2407\",\"object\":\"model\",\"created\":1742216611,\"owned_by\":\"mistralai\",\"capabilities\":{\"completion_chat\":true,\"completion_fim\":false,\"function_calling\":true,\"fine_tuning\":false,\"vision\":false},\"name\":\"codestral-mamba-2407\",\"description\":\"Official codestral-mamba-2407 Mistral AI model\",\"max_context_length\":262144,\"aliases\":[\"open-codestral-mamba\",\"codestral-mamba-latest\"],\"deprecation\":null,\"default_model_temperature\":0.7,\"type\":\"base\"},{\"id\":\"open-codestral-mamba\",\"object\":\"model\",\"created\":1742216611,\"owned_by\":\"mistralai\",\"capabilities\":{\"completion_chat\":true,\"completion_fim\":false,\"function_calling\":true,\"fine_tuning\":false,\"vision\":false},\"name\":\"codestral-mamba-2407\",\"description\":\"Official codestral-mamba-2407 Mistral AI model\",\"max_context_length\":262144,\"aliases\":[\"codestral-mamba-2407\",\"codestral-mamba-latest\"],\"deprecation\":null,\"default_model_temperature\":0.7,\"type\":\"base\"},{\"id\":\"codestral-mamba-latest\",\"object\":\"model\",\"created\":1742216611,\"owned_by\":\"mistralai\",\"capabilities\":{\"completion_chat\":true,\"completion_fim\":false,\"function_calling\":true,\"fine_tuning\":false,\"vision\":false},\"name\":\"codestral-mamba-2407\",\"description\":\"Official codestral-mamba-2407 Mistral AI model\",\"max_context_length\":262144,\"aliases\":[\"codestral-mamba-2407\",\"open-codestral-mamba\"],\"deprecation\":null,\"default_model_temperature\":0.7,\"type\":\"base\"},{\"id\":\"pixtral-12b-2409\",\"object\":\"model\",\"created\":1742216611,\"owned_by\":\"mistralai\",\"capabilities\":{\"completion_chat\":true,\"completion_fim\":false,\"function_calling\":true,\"fine_tuning\":false,\"vision\":true},\"name\":\"pixtral-12b-2409\",\"description\":\"Official pixtral-12b-2409 Mistral AI model\",\"max_context_length\":131072,\"aliases\":[\"pixtral-12b\",\"pixtral-12b-latest\"],\"deprecation\":null,\"default_model_temperature\":0.3,\"type\":\"base\"},{\"id\":\"pixtral-12b\",\"object\":\"model\",\"created\":1742216611,\"owned_by\":\"mistralai\",\"capabilities\":{\"completion_chat\":true,\"completion_fim\":false,\"function_calling\":true,\"fine_tuning\":false,\"vision\":true},\"name\":\"pixtral-12b-2409\",\"description\":\"Official pixtral-12b-2409 Mistral AI model\",\"max_context_length\":131072,\"aliases\":[\"pixtral-12b-2409\",\"pixtral-12b-latest\"],\"deprecation\":null,\"default_model_temperature\":0.3,\"type\":\"base\"},{\"id\":\"pixtral-12b-latest\",\"object\":\"model\",\"created\":1742216611,\"owned_by\":\"mistralai\",\"capabilities\":{\"completion_chat\":true,\"completion_fim\":false,\"function_calling\":true,\"fine_tuning\":false,\"vision\":true},\"name\":\"pixtral-12b-2409\",\"description\":\"Official pixtral-12b-2409 Mistral AI model\",\"max_context_length\":131072,\"aliases\":[\"pixtral-12b-2409\",\"pixtral-12b\"],\"deprecation\":null,\"default_model_temperature\":0.3,\"type\":\"base\"},{\"id\":\"mistral-small-2501\",\"object\":\"model\",\"created\":1742216611,\"owned_by\":\"mistralai\",\"capabilities\":{\"completion_chat\":true,\"completion_fim\":false,\"function_calling\":true,\"fine_tuning\":false,\"vision\":false},\"name\":\"mistral-small-2501\",\"description\":\"Official mistral-small-2501 Mistral AI model\",\"max_context_length\":32768,\"aliases\":[\"mistral-small-latest\"],\"deprecation\":null,\"default_model_temperature\":0.3,\"type\":\"base\"},{\"id\":\"mistral-small-latest\",\"object\":\"model\",\"created\":1742216611,\"owned_by\":\"mistralai\",\"capabilities\":{\"completion_chat\":true,\"completion_fim\":false,\"function_calling\":true,\"fine_tuning\":false,\"vision\":false},\"name\":\"mistral-small-2501\",\"description\":\"Official mistral-small-2501 Mistral AI model\",\"max_context_length\":32768,\"aliases\":[\"mistral-small-2501\"],\"deprecation\":null,\"default_model_temperature\":0.3,\"type\":\"base\"},{\"id\":\"mistral-saba-2502\",\"object\":\"model\",\"created\":1742216611,\"owned_by\":\"mistralai\",\"capabilities\":{\"completion_chat\":true,\"completion_fim\":false,\"function_calling\":true,\"fine_tuning\":false,\"vision\":false},\"name\":\"mistral-saba-2502\",\"description\":\"Official mistral-saba-2502 Mistral AI model\",\"max_context_length\":32768,\"aliases\":[\"mistral-saba-latest\"],\"deprecation\":null,\"default_model_temperature\":0.3,\"type\":\"base\"},{\"id\":\"mistral-saba-latest\",\"object\":\"model\",\"created\":1742216611,\"owned_by\":\"mistralai\",\"capabilities\":{\"completion_chat\":true,\"completion_fim\":false,\"function_calling\":true,\"fine_tuning\":false,\"vision\":false},\"name\":\"mistral-saba-2502\",\"description\":\"Official mistral-saba-2502 Mistral AI model\",\"max_context_length\":32768,\"aliases\":[\"mistral-saba-2502\"],\"deprecation\":null,\"default_model_temperature\":0.3,\"type\":\"base\"},{\"id\":\"mistral-embed\",\"object\":\"model\",\"created\":1742216611,\"owned_by\":\"mistralai\",\"capabilities\":{\"completion_chat\":false,\"completion_fim\":false,\"function_calling\":false,\"fine_tuning\":false,\"vision\":false},\"name\":\"mistral-embed\",\"description\":\"Official mistral-embed Mistral AI model\",\"max_context_length\":32768,\"aliases\":[],\"deprecation\":null,\"default_model_temperature\":null,\"type\":\"base\"},{\"id\":\"mistral-moderation-2411\",\"object\":\"model\",\"created\":1742216611,\"owned_by\":\"mistralai\",\"capabilities\":{\"completion_chat\":false,\"completion_fim\":false,\"function_calling\":false,\"fine_tuning\":false,\"vision\":false},\"name\":\"mistral-moderation-2411\",\"description\":\"Official mistral-moderation-2411 Mistral AI model\",\"max_context_length\":32768,\"aliases\":[\"mistral-moderation-latest\"],\"deprecation\":null,\"default_model_temperature\":null,\"type\":\"base\"},{\"id\":\"mistral-moderation-latest\",\"object\":\"model\",\"created\":1742216611,\"owned_by\":\"mistralai\",\"capabilities\":{\"completion_chat\":false,\"completion_fim\":false,\"function_calling\":false,\"fine_tuning\":false,\"vision\":false},\"name\":\"mistral-moderation-2411\",\"description\":\"Official mistral-moderation-2411 Mistral AI model\",\"max_context_length\":32768,\"aliases\":[\"mistral-moderation-2411\"],\"deprecation\":null,\"default_model_temperature\":null,\"type\":\"base\"},{\"id\":\"mistral-ocr-2503\",\"object\":\"model\",\"created\":1742216611,\"owned_by\":\"mistralai\",\"capabilities\":{\"completion_chat\":false,\"completion_fim\":false,\"function_calling\":false,\"fine_tuning\":false,\"vision\":false},\"name\":\"mistral-ocr-2503\",\"description\":\"Official mistral-ocr-2503 Mistral AI model\",\"max_context_length\":32768,\"aliases\":[\"mistral-ocr-latest\"],\"deprecation\":null,\"default_model_temperature\":null,\"type\":\"base\"},{\"id\":\"mistral-ocr-latest\",\"object\":\"model\",\"created\":1742216611,\"owned_by\":\"mistralai\",\"capabilities\":{\"completion_chat\":false,\"completion_fim\":false,\"function_calling\":false,\"fine_tuning\":false,\"vision\":false},\"name\":\"mistral-ocr-2503\",\"description\":\"Official mistral-ocr-2503 Mistral AI model\",\"max_context_length\":32768,\"aliases\":[\"mistral-ocr-2503\"],\"deprecation\":null,\"default_model_temperature\":null,\"type\":\"base\"}]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100 20940  100 20940    0     0  41059      0 --:--:-- --:--:-- --:--:-- 41220\n"
     ]
    }
   ],
   "source": [
    "!curl -X GET \"https://api.mistral.ai/v1/models\" -H \"Authorization: Bearer ADnLliQZAzgHIIRWzdTwSRCsGeqSItbW\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620f4872-44d4-48ee-91bf-de9bc6e9d933",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
