import torch
import chromadb
import streamlit as st
import speech_recognition as sr
import requests
import tempfile
from gtts import gTTS
import os
import yfinance as yf  # ‚úÖ New addition for stock price fetching
import re
from io import BytesIO
import spacy

# ‚úÖ Load spaCy NER model (make sure you've installed it!)
nlp = spacy.load("en_core_web_lg")
# ‚úÖ ChromaDB Setup
chroma_client = chromadb.PersistentClient(path="./chroma_db")
collection = chroma_client.get_collection(name="finance_docs")

# ‚úÖ Force GPU if available
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# ‚úÖ API Key for Mistral
MISTRAL_API_KEY = ""  # Replace with your actual API key

# ‚úÖ Streamlit UI
st.set_page_config(page_title="üí∞ Finance RAG AI", layout="wide")
st.title("üí∞ Finance RAG AI - Chat Mode")

# ‚úÖ Initialize session state for chat memory
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []  # Stores full chat history

if "user_query" not in st.session_state:
    st.session_state.user_query = ""  # Stores ongoing user query

# ‚úÖ Function to handle voice input
def transcribe_audio():
    recognizer = sr.Recognizer()
    with sr.Microphone() as source:
        st.sidebar.write("üó£Ô∏è Listening... Speak now!")
        recognizer.adjust_for_ambient_noise(source)  # Noise reduction
        
        try:
            audio = recognizer.listen(source, timeout=10, phrase_time_limit=8)  # Increased timeout
            query = recognizer.recognize_google(audio)  # Convert to text
            return query
        except sr.WaitTimeoutError:
            st.sidebar.error("‚è≥ No speech detected. Please try again.")
        except sr.UnknownValueError:
            st.sidebar.error("‚ùå Could not understand the audio.")
        except sr.RequestError:
            st.sidebar.error("‚ùå Speech recognition service unavailable.")
    return ""

# ‚úÖ Retrieve documents from ChromaDB
def query_chromadb(user_query):
    results = collection.query(query_texts=[user_query], n_results=3)
    return results['documents'][0] if results['documents'] else []


# ‚úÖ Function to call LLM for query analysis, company detection & ticker retrieval
def analyze_query_with_llm(user_query):
    """
    Calls Mistral LLM to:
    - Determine query type (stock_price / general).
    - Extract company/organization names.
    - Provide corresponding stock ticker symbols.
    """
    try:
        chat_context = [
            {"role": "system", "content": """You are a financial AI assistant.
                - Detect if the user query is related to stock prices or general finance.
                - Extract company/brand names from the query.
                - Provide their respective stock ticker symbols.
                - If no valid company/ticker is found, return 'None'.
                
                Your response should be in JSON format:
                {"query_type": "stock_price" or "general", "companies": [{"name": "Tesla", "ticker": "TSLA"}, {"name": "Apple", "ticker": "AAPL"}]}
            """},
            {"role": "user", "content": user_query}
        ]

        response = requests.post(
            "https://api.mistral.ai/v1/chat/completions",
            headers={"Authorization": f"Bearer {MISTRAL_API_KEY}"},
            json={
                "model": "open-mistral-7b",
                "messages": chat_context,
                "max_tokens": 200,
                "temperature": 0.3,
                "top_p": 1,
                "stream": False,
            },
        )

        response_json = response.json()
        llm_result = response_json.get("choices", [{}])[0].get("message", {}).get("content", "").strip()

        # ‚úÖ Convert response to JSON
        import json
        llm_data = json.loads(llm_result)

        return llm_data  # Expected format: {"query_type": "stock_price", "companies": [{"name": "Tesla", "ticker": "TSLA"}]}

    except Exception as e:
        return {"query_type": "general", "companies": []}

# ‚úÖ Function to fetch stock price
def fetch_stock_price(ticker):
    """
    Fetches the latest stock price for a given ticker symbol.
    """
    try:
        stock = yf.Ticker(ticker)
        price = stock.history(period="1d")["Close"].iloc[-1]
        return f"The latest stock price of {ticker} is **${price:.2f}**."
    except Exception as e:
        return f"‚ùå Unable to fetch stock price for '{ticker}'. Error: {str(e)}"


# ‚úÖ Generate Response using Mistral API with Chat History
def generate_response(query):
    llm_result = analyze_query_with_llm(user_query)

    query_type = llm_result.get("query_type", "general")
    companies = llm_result.get("companies", [])
    if query_type == "stock_price":
        if not companies:
            return "‚ùå No company names detected. Please specify a valid company."

        response_messages = []
        for company in companies:
            name = company.get("name")
            ticker = company.get("ticker")
            if ticker:
                stock_price = fetch_stock_price(ticker)
                response_messages.append(f"üìà **{name} ({ticker})**: {stock_price}")
            else:
                response_messages.append(f"‚ùå Unable to find stock ticker for **{name}**.")

        return "\n\n".join(response_messages)
        
    # ‚úÖ Otherwise, proceed with normal response retrieval
    context_docs = query_chromadb(query)
    if not context_docs:
        return "‚ùå No relevant documents found in ChromaDB."

    context = "\n".join([f"- {doc}" for doc in context_docs])[:1024]

    # ‚úÖ Maintain Chat History for Context
    chat_context = [{"role": "system", "content": context}]  # Start with retrieved docs
    chat_context.extend(st.session_state.chat_history)  # Add previous messages
    chat_context.append({"role": "user", "content": query})  # Add latest query

    # Mistral API Call
    response = requests.post(
        "https://api.mistral.ai/v1/chat/completions",
        headers={"Authorization": f"Bearer {MISTRAL_API_KEY}"},
        json={
            "model": "open-mistral-7b",
            "messages": chat_context,
            "max_tokens": 200,
            "temperature": 0.3,
            "top_p": 1,
            "stream": False,
        },
    )

    if response.status_code == 200:
        return response.json()["choices"][0]["message"]["content"]
    else:
        return f"‚ùå Error: {response.status_code} - {response.json()}"

# ‚úÖ Chat Input Bar with Voice Option
col1, col2 = st.columns([8, 1])
with col1:
    user_query = st.text_input(
        "Type your message:",
        value=st.session_state.user_query,
        key=str(len(st.session_state.chat_history))  # Dynamic key to clear input field
    )

with col2:
    use_voice = st.button("üéôÔ∏è Speak")

# ‚úÖ If Voice Button is Clicked, Convert Speech to Text & Append
if use_voice:
    voice_text = transcribe_audio()
    if voice_text:
        st.session_state.user_query += " " + voice_text  # Append to text bar
        st.rerun()  # Update UI dynamically
# ‚úÖ Function: Convert Text to Speech (Using gTTS)
def speak_text(text):
    tts = gTTS(text=text, lang="en")
    audio_bytes = BytesIO()
    tts.save(audio_bytes)
    return audio_bytes.getvalue()
    
# ‚úÖ Get Answer Button
if st.button("üîç Get Answer"):
    if user_query.strip():  # Ensure non-empty query
        st.session_state.user_query = user_query  # Store query
        st.write("üîÑ **Processing your request...**")
        response = generate_response(user_query)

        # ‚úÖ Append conversation to chat history
        st.session_state.chat_history.append({"role": "user", "content": user_query})
        st.session_state.chat_history.append({"role": "assistant", "content": response})

        '''# ‚úÖ Convert AI response to speech using gTTS
        tts = gTTS(text=response, lang="en")
        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=".mp3")
        tts.save(temp_file.name)

        # ‚úÖ Check if file exists before playing
        if os.path.exists(temp_file.name):
            st.audio(temp_file.name, format="audio/mp3")
        else:
            st.error("‚ùå Error: Audio file not found. Please try again.")

        # ‚úÖ Display Audio Player in UI
        st.audio(temp_file.name, format="audio/mp3")'''
        st.write("### üìù Chat History")
        for msg in st.session_state.chat_history:
            role = "üë§ User" if msg["role"] == "user" else "ü§ñ AI"
            st.write(f"**{role}:** {msg['content']}")

        # ‚úÖ Play Audio Response
        #st.audio(speak_text(response), format="audio/mp3")
    else:
        st.warning("‚ö†Ô∏è Please enter a question.")
        # ‚úÖ Clear input field after submission
    st.session_state.user_query = ""  
    #st.rerun()  # Refresh UI dynamically

# ‚úÖ Sidebar Info
st.sidebar.subheader("‚ÑπÔ∏è Info")
st.sidebar.write("This **Finance RAG AI** retrieves finance documents from ChromaDB and uses **Mistral-7B** for answers.")
st.sidebar.write("üí° **Now supports live stock price fetching via Yahoo Finance!** üìà")


